{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8f7817",
   "metadata": {},
   "source": [
    "## Serializing Component\n",
    "\n",
    "Autogen provides us a way via which we can easily serialize/deserialize components.\n",
    "\n",
    "- **Serialization** : It is the process of converting an object into a stream of bytes or a string representation.\n",
    "- **Deserialization** : It is the process of converting a stream of bytes or a string representation into an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21bd262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_agentchat.teams import SelectorGroupChat\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "## model client\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d672813",
   "metadata": {},
   "source": [
    "#### This is useful for debudding, visualization and even when we want to share our work with others\n",
    "\n",
    "\n",
    "## Termination Condition\n",
    "\n",
    "Here we can convert the termination condition object into a json string which can be used for string and can be desirealized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_message_termination = MaxMessageTermination(10)\n",
    "text_mention_termination = TextMentionTermination(\"STOP\")\n",
    "\n",
    "final_termination = text_mention_termination & max_message_termination\n",
    "\n",
    "## Serializing dumping the component to model\n",
    "final_termination_config = final_termination.dump_component()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534f663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"provider\":\"autogen_agentchat.base.AndTerminationCondition\",\"component_type\":\"termination\",\"version\":1,\"component_version\":1,\"description\":null,\"label\":\"AndTerminationCondition\",\"config\":{\"conditions\":[{\"provider\":\"autogen_agentchat.conditions.TextMentionTermination\",\"component_type\":\"termination\",\"version\":1,\"component_version\":1,\"description\":\"Terminate the conversation if a specific text is mentioned.\",\"label\":\"TextMentionTermination\",\"config\":{\"text\":\"STOP\"}},{\"provider\":\"autogen_agentchat.conditions.MaxMessageTermination\",\"component_type\":\"termination\",\"version\":1,\"component_version\":1,\"description\":\"Terminate the conversation after a maximum number of messages have been exchanged.\",\"label\":\"MaxMessageTermination\",\"config\":{\"max_messages\":10,\"include_agent_event\":false}}]}}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Serializing converting model to json string\n",
    "final_termination_config.model_dump_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99126ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deserializing\n",
    "new_final_termination = final_termination.load_component(final_termination_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bdb770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen_agentchat.base._termination.AndTerminationCondition at 0x253bc6b7020>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_final_termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96fd0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen_agentchat.base._termination.AndTerminationCondition at 0x253bc8d6540>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_termination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b450b9",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Now based on same idea we can serialize and deserialize agents as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7072f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name = 'assistant',\n",
    "    model_client=model_client,\n",
    "    system_message='You are a helpful assistant who can solve to solve tasks.'\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(name = 'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ddc4951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComponentModel(provider='autogen_agentchat.agents.UserProxyAgent', component_type='agent', version=1, component_version=1, description='An agent that can represent a human user through an input function.', label='UserProxyAgent', config={'name': 'user', 'description': 'A human user'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.dump_component()\n",
    "user_proxy.dump_component()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af925f7",
   "metadata": {},
   "source": [
    "#### Dumping the userproxy agent as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4faf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"user_proxy_dump.json\",\"w\") as file:\n",
    "    json.dump(user_proxy.dump_component().model_dump(), file,indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b4896c",
   "metadata": {},
   "source": [
    "#### Now loding the agent back from user_proxy_dump.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cba119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_proxy_dump.json','r') as f:\n",
    "    user_config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66d9d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent_new = user_proxy.load_component(user_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c01e0e",
   "metadata": {},
   "source": [
    "## Team Serializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4559d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[agent, user_agent_new],\n",
    "    termination_condition=new_final_termination\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d325f8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import SecretStr\n",
    "team_config = team.dump_component()\n",
    "\n",
    "with open('team_dump.json','w') as f:\n",
    "    json.dump(team_config.model_dump(), f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7aee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
